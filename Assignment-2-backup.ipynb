{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import csv\n",
    "import numpy\n",
    "import math\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../datasets/review.json\"\n",
    "f = open(path, 'r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/coraxyc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "punctuation.add('\\n')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "numpy.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(50000):\n",
    "    dataset.append(eval(f.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)\n",
    "train = dataset[:25000]\n",
    "valid = dataset[25000:37500]\n",
    "test = dataset[37500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## contained punctuation, unstemmed words, top 1000 words from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39264"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed = True\n",
    "stopped = True\n",
    "Xtrain = getX(train, 'unigrams', 'keep_punct_contained', not stemmed, not stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'unigrams', 'keep_punct_contained', not stemmed, not stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## contained punctuation, unstemmed words, top 1000 words from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61608"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed = True\n",
    "Xtrain = getX(train, 'unigrams', 'keep_punct_contained', not stemmed, not stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'unigrams', 'keep_punct_contained', not stemmed, not stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separated punctuation, unstemmed words, top 1000 words from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41504"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = getX(train, 'unigrams', 'keep_punct_separate', not stemmed, not stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'unigrams', 'keep_punct_separate', not stemmed, not stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separated punctuation, unstemmed words, top 1000 words from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63992"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = getX(train, 'unigrams', 'keep_punct_separate', not stemmed, not stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'unigrams', 'keep_punct_separate', not stemmed, not stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removed punctuation, unstemmed words, unstopped, top 1000 words from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63576"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = getX(train, 'unigrams', 'remove_punct', not stemmed, not stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'unigrams', 'remove_punct', not stemmed, not stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separated punctuation, unstemmed words, stopped, top 1000 words from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63464"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = getX(train, 'unigrams', 'keep_punct_separate', not stemmed, stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'unigrams', 'keep_punct_separate', not stemmed, stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separated punctuation, stemmed words, top 1000 words from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63688"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = getX(train, 'unigrams', 'keep_punct_separate', stemmed, stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'unigrams', 'keep_punct_separate', stemmed, stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removed punctuation, stemmed words, top 1000 words from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63224"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = getX(train, 'unigrams', 'remove_punct', stemmed, stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'unigrams', 'remove_punct', stemmed, stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56656"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = getX(train, 'bigrams', 'keep_punct_contained', not stemmed, not stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'bigrams', 'keep_punct_contained', not stemmed, not stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44784"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = getX(train, 'bigrams', 'keep_punct_separated', not stemmed, not stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'bigrams', 'keep_punct_separated', not stemmed, not stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58392"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = getX(train, 'bigrams', 'remove_punct', not stemmed, not stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'bigrams', 'remove_punct', not stemmed, not stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = getX(train, 'bigrams', 'keep_punct_contained', not stemmed, stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'bigrams', 'keep_punct_contained', not stemmed, stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = getX(train, 'bigrams', 'remove_punct', stemmed, stopped, 'word_count')\n",
    "ytrain = [d['stars'] for d in train]\n",
    "mod = linear_model.LogisticRegression(C=1.0)\n",
    "mod.fit(Xtrain,ytrain)\n",
    "Xvalid = getX(valid, 'bigrams', 'remove_punct', stemmed, stopped, 'word_count')\n",
    "yvalid = [d['stars'] for d in valid]\n",
    "pred = mod.predict(Xvalid)\n",
    "get_accuracy(pred, yvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred, y):\n",
    "    correct_pred = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == y[i]:\n",
    "            correct_pred += 1\n",
    "    return correct_pred / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getX(reviews, i, j, stemmed, stopped, k):\n",
    "    if k == 'word_count':\n",
    "        return getX_word_count(reviews, i, j, stemmed, stopped, k)\n",
    "    elif k == 'tf_idf':\n",
    "        return getX_tf_idf(reviews, i, j, stemmed, stopped, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getX_word_count(reviews, i, j, stemmed, stopped, k):\n",
    "    wordCounts = get_wordcounts(dataset, i, j, stemmed, stopped, k)\n",
    "    words = get_n_most_common_words(wordCounts, 1000)\n",
    "    wordId = dict(zip(words, range(len(words))))\n",
    "    wordSet = set(words)\n",
    "\n",
    "    X = []\n",
    "    for review in reviews:\n",
    "        feat = [0] * len(words)\n",
    "        r_set = get_review_words(review, j)\n",
    "        prev = ''\n",
    "        for w in r_set:\n",
    "            if stemmed:\n",
    "                w = stemmer.stem(w)\n",
    "            if stopped and w in stop_words:\n",
    "                continue\n",
    "            if i == 'unigrams' and w in wordSet:\n",
    "                feat[wordId[w]] += 1\n",
    "            elif i == 'bigrams' and prev != '' and (prev + ' ' + w) in wordSet:\n",
    "                feat[wordId[prev + ' ' + w]] += 1\n",
    "            prev = w\n",
    "        \n",
    "        feat.append(1) #offset\n",
    "        X.append(feat)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getX_tf_idf(reviews, i, j, stemmed, stopped, k):\n",
    "    wordCounts = get_wordcounts(reviews, i, j, stemmed, stopped, k)\n",
    "    words = get_n_most_common_words(wordCounts, 1000)\n",
    "    wordId = dict(zip(words, range(len(words))))\n",
    "    wordSet = set(words)\n",
    "\n",
    "    tf_scores = [0] * len(words)\n",
    "    df_scores = get_df_scores(reviews, words, wordId, j)\n",
    "    tf_idf_scores = [0] * len(words)\n",
    "    \n",
    "    idf_scores = []\n",
    "    for score in df_scores:\n",
    "        if score == 0:\n",
    "            idf_scores.append(0)\n",
    "        else:\n",
    "            idf_scores.append(math.log10(len(words) / score))\n",
    "    \n",
    "    X = []\n",
    "    for review in reviews:\n",
    "        r_set = get_review_words(review, j)\n",
    "        for w in r_set:\n",
    "            if stemmed:\n",
    "                w = stemmer.stem(w)\n",
    "            if stopped and w in stop_words:\n",
    "                continue\n",
    "            if w in wordSet:\n",
    "                tf_scores[wordId[w]] += 1\n",
    "\n",
    "        feat = [i * j for (i,j) in zip(tf_scores,idf_scores)]\n",
    "        X.append(feat)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordcounts(reviews, i, j, stemmed, stopped, k):\n",
    "    wordCounts = defaultdict(int)\n",
    "\n",
    "    for review in reviews:\n",
    "        r_set = get_review_words(review, j)\n",
    "        prev = ''\n",
    "        for w in r_set:\n",
    "            if stemmed:\n",
    "                w = stemmer.stem(w)\n",
    "            if stopped and w in stop_words:\n",
    "                continue\n",
    "            if i == 'unigrams':\n",
    "                wordCounts[w] += 1\n",
    "            elif prev != '' and i == 'bigrams':\n",
    "                wordCounts[prev + ' ' + w] += 1\n",
    "            prev = w\n",
    "    return wordCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_most_common_words(wordCounts, n):\n",
    "    counts = [(wordCounts[w], w) for w in wordCounts]\n",
    "    counts.sort()\n",
    "    counts.reverse()\n",
    "    words = [x[1] for x in counts[:n]]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_words(review, j):\n",
    "    r = ''\n",
    "    if j == 'remove_punct':\n",
    "        r = ''.join([c for c in review['text'].lower() if not c in punctuation])\n",
    "    elif j == 'keep_punct_contained':\n",
    "        r = review['text']\n",
    "    elif j == 'keep_punct_separate':\n",
    "        for c in review['text'].lower():\n",
    "            if not c in punctuation:\n",
    "                r += c\n",
    "            else:\n",
    "                r += (' ' + c + ' ')\n",
    "    return r.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_scores(reviews, words, wordId, j):\n",
    "    df_scores = [0] * len(words)\n",
    "    for review in reviews:\n",
    "        r_set = get_review_words(review, j)\n",
    "        for w in words:\n",
    "            if w in r_set:\n",
    "                df_scores[wordId[w]] += 1\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
